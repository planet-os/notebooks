{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing ERA5 Data on S3\n",
    "\n",
    "This notebook explores how to access ERA5 data stored on a public S3 bucket as part of the [AWS Public Dataset program.](https://aws.amazon.com/opendata/public-datasets). We'll examine how the data is organized in S3, download sample files in NetCDF format, and perform some simple analysis on the data.\n",
    "\n",
    "ERA5 provides hourly estimates of a large number of atmospheric, land and oceanic climate variables. The data cover the Earth on a 30km grid and resolve the atmosphere using 137 levels from the surface up to a height of 80km.\n",
    "\n",
    "A first segment of the ERA5 dataset is now available for public use (2008 to within 3 months of real time). Subsequent releases of ERA5 will cover the earlier decades. The entire ERA5 dataset from 1950 to present is expected to be available for use by early 2019.\n",
    "\n",
    "The ERA5 data available on S3 contains an initial subset of 15 near surface variables. If there are additional variables you would like to see on S3, please contact [datahub@intertrust.com](mailto:datahub@intertrust.com?subject=ERA5 data on S3) with your request. We'll be evaluating the feedback we receive and potentially adding more variables in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize notebook environment.\n",
    "%matplotlib inline\n",
    "import boto3\n",
    "import botocore\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up S3 Access Using Boto\n",
    "\n",
    "We'll use `boto` to access the S3 bucket. Below, we'll set the bucket ID and create a resource to access it.\n",
    "\n",
    "Note that although the bucket is public, `boto` requires the presence of an AWS access key and secret key to use a s3 resource. To request data anonymously, we'll use a low-level client instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "era5_bucket = 'era5-pds'\n",
    "\n",
    "# AWS access / secret keys required\n",
    "# s3 = boto3.resource('s3')\n",
    "# bucket = s3.Bucket(era5_bucket)\n",
    "\n",
    "# No AWS keys required\n",
    "client = boto3.client('s3', config=botocore.client.Config(signature_version=botocore.UNSIGNED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ERA5 Data Structure on S3\n",
    "\n",
    "The ERA5 data is chunked into distinct NetCDF files per variable, each containing a month of hourly data. These files are organized in the S3 bucket by year, month, and variable name.\n",
    "\n",
    "The data is structured as follows:\n",
    "\n",
    "    /{year}/{month}/main.nc\n",
    "                   /data/{var1}.nc\n",
    "                        /{var2}.nc\n",
    "                        /{....}.nc\n",
    "                        /{varN}.nc\n",
    "\n",
    "where year is expressed as four digits (e.g. YYYY) and month as two digits (e.g. MM). Individual data variables (var1 through varN) use names corresponding to CF standard names convention plus any applicable additional info, such as vertical coordinate.\n",
    "\n",
    "For example, the full file path for air temperature for January 2008 is:\n",
    "\n",
    "    /2008/01/data/air_temperature_at_2_metres.nc\n",
    "\n",
    "Note that due to the nature of the ERA5 forecast timing, which is run twice daily at 06:00 and 18:00 UTC, the monthly data file begins with data from 07:00 on the first of the month and continues through 06:00 of the following month. We'll see this in the coordinate values of a data file we download later in the notebook.\n",
    "\n",
    "Granule variable structure and metadata attributes are stored in `main.nc`. This file contains coordinate and auxiliary variable data. This file is also annotated using NetCDF CF metadata conventions.\n",
    "\n",
    "We can use the paginate method to list the top level key prefixes in the bucket, which corresponds to the available years of ERA5 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008/\n",
      "2009/\n",
      "2010/\n",
      "2011/\n",
      "2012/\n",
      "2013/\n",
      "2014/\n",
      "2015/\n",
      "2016/\n",
      "2017/\n",
      "2018/\n"
     ]
    }
   ],
   "source": [
    "paginator = client.get_paginator('list_objects')\n",
    "result = paginator.paginate(Bucket=era5_bucket, Delimiter='/')\n",
    "for prefix in result.search('CommonPrefixes'):\n",
    "    print(prefix.get('Prefix'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the objects available for a specific month using boto's [list_objects_v2](http://boto3.readthedocs.io/en/latest/reference/services/s3.html#S3.Client.list_objects_v2) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 32 objects available for January, 2018\n",
      "--\n",
      "2018/01/data/air_pressure_at_mean_sea_level.nc\n",
      "2018/01/data/air_temperature_at_2_metres.nc\n",
      "2018/01/data/air_temperature_at_2_metres_1hour_Maximum.nc\n",
      "2018/01/data/air_temperature_at_2_metres_1hour_Maximum.nc4\n",
      "2018/01/data/air_temperature_at_2_metres_1hour_Minimum.nc\n",
      "2018/01/data/air_temperature_at_2_metres_1hour_Minimum.nc4\n",
      "2018/01/data/dew_point_temperature_at_2_metres.nc\n",
      "2018/01/data/dew_point_temperature_at_2_metres.nc4\n",
      "2018/01/data/eastward_wind_at_100_metres.nc\n",
      "2018/01/data/eastward_wind_at_100_metres.nc4\n",
      "2018/01/data/eastward_wind_at_10_metres.nc\n",
      "2018/01/data/eastward_wind_at_10_metres.nc4\n",
      "2018/01/data/integral_wrt_time_of_surface_direct_downwelling_shortwave_flux_in_air_1hour_Accumulation.nc\n",
      "2018/01/data/integral_wrt_time_of_surface_direct_downwelling_shortwave_flux_in_air_1hour_Accumulation.nc4\n",
      "2018/01/data/lwe_thickness_of_surface_snow_amount.nc\n",
      "2018/01/data/lwe_thickness_of_surface_snow_amount.nc4\n",
      "2018/01/data/northward_wind_at_100_metres.nc\n",
      "2018/01/data/northward_wind_at_100_metres.nc4\n",
      "2018/01/data/northward_wind_at_10_metres.nc\n",
      "2018/01/data/northward_wind_at_10_metres.nc4\n",
      "2018/01/data/precipitation_amount_1hour_Accumulation.nc\n",
      "2018/01/data/precipitation_amount_1hour_Accumulation.nc4\n",
      "2018/01/data/sea_surface_temperature.nc\n",
      "2018/01/data/sea_surface_temperature.nc4\n",
      "2018/01/data/sea_surface_wave_mean_period.nc\n",
      "2018/01/data/sea_surface_wind_wave_from_direction.nc\n",
      "2018/01/data/significant_height_of_wind_and_swell_waves.nc\n",
      "2018/01/data/snow_density.nc\n",
      "2018/01/data/snow_density.nc4\n",
      "2018/01/data/surface_air_pressure.nc\n",
      "2018/01/data/surface_air_pressure.nc4\n",
      "2018/01/main.nc\n"
     ]
    }
   ],
   "source": [
    "keys = []\n",
    "date = datetime.date(2018,1,1) # update to desired date\n",
    "prefix = date.strftime('%Y/%m/')\n",
    "\n",
    "response = client.list_objects_v2(Bucket=era5_bucket, Prefix=prefix)\n",
    "response_meta = response.get('ResponseMetadata')\n",
    "\n",
    "if response_meta.get('HTTPStatusCode') == 200:\n",
    "    contents = response.get('Contents')\n",
    "    if contents == None:\n",
    "        print(\"No objects are available for %s\" % date.strftime('%B, %Y'))\n",
    "    else:\n",
    "        for obj in contents:\n",
    "            keys.append(obj.get('Key'))\n",
    "        print(\"There are %s objects available for %s\\n--\" % (len(keys), date.strftime('%B, %Y')))\n",
    "        for k in keys:\n",
    "            print(k)\n",
    "else:\n",
    "    print(\"There was an error with your request.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Files \n",
    "\n",
    "Let's download `main.nc` file for that month and use **xarray** to inspect the metadata relating to the data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xarray.Dataset {\n",
      "dimensions:\n",
      "\tlat = 640 ;\n",
      "\tlon = 1280 ;\n",
      "\tnv = 2 ;\n",
      "\ttime0 = 744 ;\n",
      "\ttime1 = 744 ;\n",
      "\n",
      "variables:\n",
      "\tfloat64 time0(time0) ;\n",
      "\t\ttime0:units = seconds since 1970-01-01 ;\n",
      "\t\ttime0:standard_name = time ;\n",
      "\tfloat32 lat(lat) ;\n",
      "\t\tlat:standard_name = latitude ;\n",
      "\t\tlat:long_name = latitude ;\n",
      "\t\tlat:units = degrees_north ;\n",
      "\tfloat32 lon(lon) ;\n",
      "\t\tlon:standard_name = longitude ;\n",
      "\t\tlon:long_name = longitude ;\n",
      "\t\tlon:units = degrees_east ;\n",
      "\tfloat64 time1(time1) ;\n",
      "\t\ttime1:units = seconds since 1970-01-01 ;\n",
      "\t\ttime1:standard_name = time ;\n",
      "\t\ttime1:bounds = time1_bounds ;\n",
      "\tfloat32 northward_wind_at_10_metres(time0, lat, lon) ;\n",
      "\t\tnorthward_wind_at_10_metres:standard_name = northward_wind ;\n",
      "\t\tnorthward_wind_at_10_metres:units = m s**-1 ;\n",
      "\t\tnorthward_wind_at_10_metres:long_name = 10 metre V wind component ;\n",
      "\t\tnorthward_wind_at_10_metres:nameECMWF = 10 metre V wind component ;\n",
      "\t\tnorthward_wind_at_10_metres:nameCDM = 10_metre_V_wind_component_surface ;\n",
      "\t\tnorthward_wind_at_10_metres:_SuperchunkSizes = [ 744  640 1280] ;\n",
      "\tfloat32 air_pressure_at_mean_sea_level(time0, lat, lon) ;\n",
      "\t\tair_pressure_at_mean_sea_level:standard_name = air_pressure_at_mean_sea_level ;\n",
      "\t\tair_pressure_at_mean_sea_level:units = Pa ;\n",
      "\t\tair_pressure_at_mean_sea_level:long_name = Mean sea level pressure ;\n",
      "\t\tair_pressure_at_mean_sea_level:nameECMWF = Mean sea level pressure ;\n",
      "\t\tair_pressure_at_mean_sea_level:nameCDM = Mean_sea_level_pressure_surface ;\n",
      "\t\tair_pressure_at_mean_sea_level:_SuperchunkSizes = [ 744  640 1280] ;\n",
      "\tfloat32 lwe_thickness_of_surface_snow_amount(time0, lat, lon) ;\n",
      "\t\tlwe_thickness_of_surface_snow_amount:standard_name = lwe_thickness_of_surface_snow_amount ;\n",
      "\t\tlwe_thickness_of_surface_snow_amount:units = m of water equivalent ;\n",
      "\t\tlwe_thickness_of_surface_snow_amount:long_name = Snow depth ;\n",
      "\t\tlwe_thickness_of_surface_snow_amount:nameECMWF = Snow depth ;\n",
      "\t\tlwe_thickness_of_surface_snow_amount:nameCDM = Snow_depth_surface ;\n",
      "\t\tlwe_thickness_of_surface_snow_amount:_SuperchunkSizes = [ 744  640 1280] ;\n",
      "\tfloat32 air_temperature_at_2_metres_1hour_Minimum(time1, lat, lon) ;\n",
      "\t\tair_temperature_at_2_metres_1hour_Minimum:standard_name = air_temperature ;\n",
      "\t\tair_temperature_at_2_metres_1hour_Minimum:units = K ;\n",
      "\t\tair_temperature_at_2_metres_1hour_Minimum:long_name = Minimum temperature at 2 metres since previous post-processing ;\n",
      "\t\tair_temperature_at_2_metres_1hour_Minimum:nameECMWF = Minimum temperature at 2 metres since previous post-processing ;\n",
      "\t\tair_temperature_at_2_metres_1hour_Minimum:nameCDM = Minimum_temperature_at_2_metres_since_previous_post-processing_surface_1_Hour_2 ;\n",
      "\t\tair_temperature_at_2_metres_1hour_Minimum:_SuperchunkSizes = [ 744  640 1280] ;\n",
      "\tfloat64 time1_bounds(time1, nv) ;\n",
      "\t\ttime1_bounds:units = seconds since 1970-01-01 ;\n",
      "\t\ttime1_bounds:_SuperchunkSizes = [744   2] ;\n",
      "\tfloat32 integral_wrt_time_of_surface_direct_downwelling_shortwave_flux_in_air_1hour_Accumulation(time1, lat, lon) ;\n",
      "\t\tintegral_wrt_time_of_surface_direct_downwelling_shortwave_flux_in_air_1hour_Accumulation:standard_name = integral_wrt_time_of_surface_direct_downwelling_shortwave_flux_in_air ;\n",
      "\t\tintegral_wrt_time_of_surface_direct_downwelling_shortwave_flux_in_air_1hour_Accumulation:units = J m**-2 ;\n",
      "\t\tintegral_wrt_time_of_surface_direct_downwelling_shortwave_flux_in_air_1hour_Accumulation:long_name = Surface solar radiation downwards ;\n",
      "\t\tintegral_wrt_time_of_surface_direct_downwelling_shortwave_flux_in_air_1hour_Accumulation:nameECMWF = Surface solar radiation downwards ;\n",
      "\t\tintegral_wrt_time_of_surface_direct_downwelling_shortwave_flux_in_air_1hour_Accumulation:nameCDM = Surface_solar_radiation_downwards_surface_1_Hour_Accumulation ;\n",
      "\t\tintegral_wrt_time_of_surface_direct_downwelling_shortwave_flux_in_air_1hour_Accumulation:_SuperchunkSizes = [ 744  640 1280] ;\n",
      "\tfloat32 northward_wind_at_100_metres(time0, lat, lon) ;\n",
      "\t\tnorthward_wind_at_100_metres:standard_name = northward_wind ;\n",
      "\t\tnorthward_wind_at_100_metres:units = m s**-1 ;\n",
      "\t\tnorthward_wind_at_100_metres:long_name = 100 metre V wind component ;\n",
      "\t\tnorthward_wind_at_100_metres:nameECMWF = 100 metre V wind component ;\n",
      "\t\tnorthward_wind_at_100_metres:nameCDM = 100_metre_V_wind_component_surface ;\n",
      "\t\tnorthward_wind_at_100_metres:_SuperchunkSizes = [ 744  640 1280] ;\n",
      "\tfloat32 air_temperature_at_2_metres_1hour_Maximum(time1, lat, lon) ;\n",
      "\t\tair_temperature_at_2_metres_1hour_Maximum:standard_name = air_temperature ;\n",
      "\t\tair_temperature_at_2_metres_1hour_Maximum:units = K ;\n",
      "\t\tair_temperature_at_2_metres_1hour_Maximum:long_name = Maximum temperature at 2 metres since previous post-processing ;\n",
      "\t\tair_temperature_at_2_metres_1hour_Maximum:nameECMWF = Maximum temperature at 2 metres since previous post-processing ;\n",
      "\t\tair_temperature_at_2_metres_1hour_Maximum:nameCDM = Maximum_temperature_at_2_metres_since_previous_post-processing_surface_1_Hour_2 ;\n",
      "\t\tair_temperature_at_2_metres_1hour_Maximum:_SuperchunkSizes = [ 744  640 1280] ;\n",
      "\tfloat32 precipitation_amount_1hour_Accumulation(time1, lat, lon) ;\n",
      "\t\tprecipitation_amount_1hour_Accumulation:standard_name = precipitation_amount ;\n",
      "\t\tprecipitation_amount_1hour_Accumulation:units = m ;\n",
      "\t\tprecipitation_amount_1hour_Accumulation:long_name = Total precipitation ;\n",
      "\t\tprecipitation_amount_1hour_Accumulation:nameECMWF = Total precipitation ;\n",
      "\t\tprecipitation_amount_1hour_Accumulation:nameCDM = Total_precipitation_1hour_Accumulation ;\n",
      "\t\tprecipitation_amount_1hour_Accumulation:_SuperchunkSizes = [ 744  640 1280] ;\n",
      "\tfloat32 surface_air_pressure(time0, lat, lon) ;\n",
      "\t\tsurface_air_pressure:standard_name = surface_air_pressure ;\n",
      "\t\tsurface_air_pressure:units = Pa ;\n",
      "\t\tsurface_air_pressure:long_name = Surface pressure ;\n",
      "\t\tsurface_air_pressure:nameECMWF = Surface pressure ;\n",
      "\t\tsurface_air_pressure:nameCDM = Surface_pressure_surface ;\n",
      "\t\tsurface_air_pressure:_SuperchunkSizes = [ 744  640 1280] ;\n",
      "\tfloat32 air_temperature_at_2_metres(time0, lat, lon) ;\n",
      "\t\tair_temperature_at_2_metres:standard_name = air_temperature ;\n",
      "\t\tair_temperature_at_2_metres:units = K ;\n",
      "\t\tair_temperature_at_2_metres:long_name = 2 metre temperature ;\n",
      "\t\tair_temperature_at_2_metres:nameECMWF = 2 metre temperature ;\n",
      "\t\tair_temperature_at_2_metres:nameCDM = 2_metre_temperature_surface ;\n",
      "\t\tair_temperature_at_2_metres:_SuperchunkSizes = [ 744  640 1280] ;\n",
      "\tfloat32 sea_surface_temperature(time0, lat, lon) ;\n",
      "\t\tsea_surface_temperature:standard_name = sea_surface_temperature ;\n",
      "\t\tsea_surface_temperature:units = K ;\n",
      "\t\tsea_surface_temperature:long_name = Sea surface temperature ;\n",
      "\t\tsea_surface_temperature:nameECMWF = Sea surface temperature ;\n",
      "\t\tsea_surface_temperature:nameCDM = Sea_surface_temperature_surface ;\n",
      "\t\tsea_surface_temperature:_SuperchunkSizes = [ 744  640 1280] ;\n",
      "\tfloat32 eastward_wind_at_100_metres(time0, lat, lon) ;\n",
      "\t\teastward_wind_at_100_metres:standard_name = eastward_wind ;\n",
      "\t\teastward_wind_at_100_metres:units = m s**-1 ;\n",
      "\t\teastward_wind_at_100_metres:long_name = 100 metre U wind component ;\n",
      "\t\teastward_wind_at_100_metres:nameECMWF = 100 metre U wind component ;\n",
      "\t\teastward_wind_at_100_metres:nameCDM = 100_metre_U_wind_component_surface ;\n",
      "\t\teastward_wind_at_100_metres:_SuperchunkSizes = [ 744  640 1280] ;\n",
      "\tfloat32 snow_density(time0, lat, lon) ;\n",
      "\t\tsnow_density:standard_name = snow_density ;\n",
      "\t\tsnow_density:units = kg m**-3 ;\n",
      "\t\tsnow_density:long_name = Snow density ;\n",
      "\t\tsnow_density:nameECMWF = Snow density ;\n",
      "\t\tsnow_density:nameCDM = Snow_density_surface ;\n",
      "\t\tsnow_density:_SuperchunkSizes = [ 744  640 1280] ;\n",
      "\tfloat32 dew_point_temperature_at_2_metres(time0, lat, lon) ;\n",
      "\t\tdew_point_temperature_at_2_metres:standard_name = dew_point_temperature ;\n",
      "\t\tdew_point_temperature_at_2_metres:units = K ;\n",
      "\t\tdew_point_temperature_at_2_metres:long_name = 2 metre dewpoint temperature ;\n",
      "\t\tdew_point_temperature_at_2_metres:nameECMWF = 2 metre dewpoint temperature ;\n",
      "\t\tdew_point_temperature_at_2_metres:nameCDM = 2_metre_dewpoint_temperature_surface ;\n",
      "\t\tdew_point_temperature_at_2_metres:_SuperchunkSizes = [ 744  640 1280] ;\n",
      "\tfloat32 eastward_wind_at_10_metres(time0, lat, lon) ;\n",
      "\t\teastward_wind_at_10_metres:standard_name = eastward_wind ;\n",
      "\t\teastward_wind_at_10_metres:units = m s**-1 ;\n",
      "\t\teastward_wind_at_10_metres:long_name = 10 metre U wind component ;\n",
      "\t\teastward_wind_at_10_metres:nameECMWF = 10 metre U wind component ;\n",
      "\t\teastward_wind_at_10_metres:nameCDM = 10_metre_U_wind_component_surface ;\n",
      "\t\teastward_wind_at_10_metres:_SuperchunkSizes = [ 744  640 1280] ;\n",
      "\n",
      "// global attributes:\n",
      "\t:source = Reanalysis ;\n",
      "\t:institution = ECMWF ;\n",
      "\t:title = \"ERA5 forecasts\" ;\n",
      "\t:history = Thu Jul  5 04:37:28 2018: ncatted /data.e1/wrk/s3_out_in/2018/01/air_pressure_at_mean_sea_level.nc -a tilte,global,d,, -a title,global,c,c,\"ERA5 forecasts\" ;\n",
      "}"
     ]
    }
   ],
   "source": [
    "metadata_file = 'main.nc'\n",
    "metadata_key = prefix + metadata_file\n",
    "client.download_file(era5_bucket, metadata_key, metadata_file)\n",
    "ds_meta = xr.open_dataset('main.nc', decode_times=False)\n",
    "ds_meta.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's acquire data for a single variable over the course of a month. Let's download air temperature for August of 2017 and open the NetCDF file using `xarray`.\n",
    "\n",
    "Note that the cell below may take some time to execute, depending on your connection speed. Most of the variable files are roughly 1 GB in size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 2017/08/data/air_temperature_at_2_metres.nc from S3...\n"
     ]
    }
   ],
   "source": [
    "# select date and variable of interest\n",
    "date = datetime.date(2017,8,1)\n",
    "var = 'air_temperature_at_2_metres'\n",
    "\n",
    "# file path patterns for remote S3 objects and corresponding local file\n",
    "s3_data_ptrn = '{year}/{month}/data/{var}.nc'\n",
    "data_file_ptrn = '{year}{month}_{var}.nc'\n",
    "\n",
    "year = date.strftime('%Y')\n",
    "month = date.strftime('%m')\n",
    "s3_data_key = s3_data_ptrn.format(year=year, month=month, var=var)\n",
    "data_file = data_file_ptrn.format(year=year, month=month, var=var)\n",
    "\n",
    "if not os.path.isfile(data_file): # check if file already exists\n",
    "    print(\"Downloading %s from S3...\" % s3_data_key)\n",
    "    client.download_file(era5_bucket, s3_data_key, data_file)\n",
    "\n",
    "ds = xr.open_dataset(data_file)\n",
    "ds.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ds.info` output above shows us that there are three dimensions to the data: lat, lon, and time0; and one data variable: air_temperature_at_2_metres. Let's inspect the coordinate values to see what they look like..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.coords.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the coordinate values, we can see that longitude is expressed as degrees east, ranging from 0 to 359.718 degrees. Latitude is expressed as degrees north, ranging from -89.784874 to 89.784874. And finally the time0 coordinate, ranging from 2017-08-01T07:00:00Z to 2017-09-01T06:00:00Z.\n",
    "\n",
    "As mentioned above, due to the forecast run timing the first forecast run of the month results in data beginning at 07:00, while the last produces data through September 1 at 06:00.\n",
    "\n",
    "## Temperature at Specific Locations\n",
    "\n",
    "Let's create a list of various locations and plot their temperature values during the month. Note that the longitude values of the coordinates below are not given in degrees east, but rather as a mix of eastward and westward values. The data's longitude coordinate is degrees east, so we'll convert these location coordinates accordingly to match the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location coordinates\n",
    "locs = [\n",
    "    {'name': 'santa_monica', 'lon': -118.496245, 'lat': 34.010341},\n",
    "    {'name': 'tallinn', 'lon': 24.753574, 'lat': 59.436962},\n",
    "    {'name': 'honolulu', 'lon': -157.835938, 'lat': 21.290014},\n",
    "    {'name': 'cape_town', 'lon': 18.423300, 'lat': -33.918861},\n",
    "    {'name': 'dubai', 'lon': 55.316666, 'lat': 25.266666},\n",
    "]\n",
    "\n",
    "# convert westward longitudes to degrees east\n",
    "for l in locs:\n",
    "    if l['lon'] < 0:\n",
    "        l['lon'] = 360 + l['lon']\n",
    "locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_locs = xr.Dataset()\n",
    "\n",
    "# interate through the locations and create a dataset\n",
    "# containing the temperature values for each location\n",
    "for l in locs:\n",
    "    name = l['name']\n",
    "    lon = l['lon']\n",
    "    lat = l['lat']\n",
    "    var_name = name\n",
    "\n",
    "    ds2 = ds.sel(lon=lon, lat=lat, method='nearest')\n",
    "\n",
    "    lon_attr = '%s_lon' % name\n",
    "    lat_attr = '%s_lat' % name\n",
    "\n",
    "    ds2.attrs[lon_attr] = ds2.lon.values.tolist()\n",
    "    ds2.attrs[lat_attr] = ds2.lat.values.tolist()\n",
    "    ds2 = ds2.rename({var : var_name}).drop(('lat', 'lon'))\n",
    "    \n",
    "    ds_locs = xr.merge([ds_locs, ds2])\n",
    "\n",
    "ds_locs.data_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Units and Create a Dataframe\n",
    "\n",
    "Temperature data in the ERA5 dataset uses Kelvin. Let's convert it to something more meaningful. I've chosen to use Fahrenheit, because as a U.S. citizen (and stubborn metric holdout) Celcius still feels foreign to me ;-)\n",
    "\n",
    "While we're at it, let's also convert the dataset to a pandas dataframe and use the describe method to display some statistics about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kelvin_to_celcius(t):\n",
    "    return t - 273.15\n",
    "\n",
    "def kelvin_to_fahrenheit(t):\n",
    "    return t * 9/5 - 459.67\n",
    "\n",
    "ds_locs_f = ds_locs.apply(kelvin_to_fahrenheit)\n",
    "\n",
    "df_f = ds_locs_f.to_dataframe()\n",
    "df_f.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Me Some Charts!\n",
    "\n",
    "Finally, let's plot the temperature data for each of the locations over the period. The first plot displays the hourly temperature for each location over the month.\n",
    "\n",
    "The second plot is a [box plot](https://en.wikipedia.org/wiki/Box_plot). A box plot is a method for graphically depicting groups of numerical data through their quartiles. The box extends from the Q1 to Q3 quartile values of the data, with a line at the median (Q2). The whiskers extend from the edges of box to show the range of the data. The position of the whiskers is set by default to 1.5 * IQR (IQR = Q3 - Q1) from the edges of the box. Outlier points are those past the end of the whiskers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readability please\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "ax = df_f.plot(figsize=(18, 10), title=\"ERA5 Air Temperature at 2 Meters\", grid=1)\n",
    "ax.set(xlabel='Date', ylabel='Air Temperature (deg F)')\n",
    "plt.show()\n",
    "\n",
    "ax = df_f.plot.box(figsize=(18, 10))\n",
    "ax.set(xlabel='Location', ylabel='Air Temperature (deg F)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions? Dubai was absolutely cooking in August, with a mean temperature of ~98째 and a high of 117째! While Honolulu was a consistent 78째 with a standard deviation of less than 1째!\n",
    "\n",
    "Questions? Feedback? Email us at [datahub@intertrust.com](mailto:datahub@intertrust.com). We also provide an API for accessing ERA5 data, for more details vis the [Planet OS Datahub](https://data.planetos.com/datasets/ecmwf_era5) or check out [another notebook example using ERA5 data.](https://github.com/planet-os/notebooks/blob/master/api-examples/ERA5_tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
